{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17121563-45d7-4e8e-a030-ae903e89f96e",
   "metadata": {
    "id": "17121563-45d7-4e8e-a030-ae903e89f96e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4966f9e-8a21-44a8-9043-57d2be5f583d",
   "metadata": {
    "id": "c4966f9e-8a21-44a8-9043-57d2be5f583d"
   },
   "outputs": [],
   "source": [
    "# Set seed and device\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6e8c3c-0fc1-4f8f-a3d2-93964a3b108b",
   "metadata": {
    "id": "8d6e8c3c-0fc1-4f8f-a3d2-93964a3b108b"
   },
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb7bc29-9620-4b86-97f0-3c9157e78617",
   "metadata": {
    "id": "2eb7bc29-9620-4b86-97f0-3c9157e78617"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "X = df.drop(columns=['smoking'])\n",
    "y = df['smoking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e25a7257-4236-4715-ab27-13dd454228c4",
   "metadata": {
    "id": "e25a7257-4236-4715-ab27-13dd454228c4"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaec34d8-1bf8-42f6-b5e8-3e57fa850992",
   "metadata": {
    "id": "aaec34d8-1bf8-42f6-b5e8-3e57fa850992"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y.values).reshape(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0984c2c9-b6ea-43ee-b520-4de6276741a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0984c2c9-b6ea-43ee-b520-4de6276741a6",
    "outputId": "cf3d4520-5bca-41b6-ac23-158e5ff99e4d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50020678-905d-4500-a1fd-d5d982bb028b",
   "metadata": {
    "id": "50020678-905d-4500-a1fd-d5d982bb028b"
   },
   "source": [
    "# Реализуем модель TabNet, которая является ондой из луччших архитектур для табличных данных\n",
    "\n",
    "Сначала реализуем GLU слои\n",
    "\n",
    "Затем слой FeatureTransformer, преобразующий исходные фичи в скрытое представление\n",
    "\n",
    "Также реализуем AttentiveTransformer, который нужен, для определения важности фичей на каждом шаге"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af3eea9f-f3d7-4a3b-85b4-d5d67b7426fc",
   "metadata": {
    "id": "af3eea9f-f3d7-4a3b-85b4-d5d67b7426fc"
   },
   "outputs": [],
   "source": [
    "class GLU(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, p=0.2):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, 2 * output_dim)\n",
    "        self.bn = nn.BatchNorm1d(2 * output_dim)\n",
    "        self.drop = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.drop(x)\n",
    "        out, gate = x.chunk(2, dim=1)\n",
    "        return out * torch.sigmoid(gate)\n",
    "\n",
    "class FeatureTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, shared=2, steps=2, hidden=32, p=0.2):\n",
    "        super().__init__()\n",
    "        self.shared = nn.ModuleList([\n",
    "            GLU(input_dim if i ==0 else hidden, hidden, p)\n",
    "            for i in range(shared)\n",
    "        ])\n",
    "        self.steps = nn.ModuleList([\n",
    "            GLU(hidden, hidden, p)\n",
    "            for _ in range(steps)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.shared:\n",
    "            x = layer(x)\n",
    "\n",
    "        step_outputs = []\n",
    "        for layer in self.steps:\n",
    "            x = layer(x)\n",
    "            step_outputs.append(x)\n",
    "        return x, step_outputs\n",
    "\n",
    "class AttentiveTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        self.bn = nn.BatchNorm1d(output_dim)\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "\n",
    "    def forward(self, x, prior):\n",
    "        x = self.fc(x)\n",
    "        x = self.bn(x)\n",
    "        x = x * prior\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab8cdf-f603-4e9b-aef3-f76c6ceb3659",
   "metadata": {
    "id": "9aab8cdf-f603-4e9b-aef3-f76c6ceb3659"
   },
   "source": [
    "# Реализуем пошаговую модель TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a488296e-c73c-4b89-bea5-a80c41f4a09a",
   "metadata": {
    "id": "a488296e-c73c-4b89-bea5-a80c41f4a09a"
   },
   "outputs": [],
   "source": [
    "class TabNetClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, n_steps=3, shared_layers=2, hidden_dim=32, gamma=1.3, sparsity=1e-4, p=0.2):\n",
    "        super().__init__()\n",
    "        self.feature_transformer = FeatureTransformer(\n",
    "            input_dim,\n",
    "            shared=shared_layers,\n",
    "            steps=n_steps,\n",
    "            hidden=hidden_dim,\n",
    "            p=p\n",
    "        )\n",
    "        self.attentive_trans = nn.ModuleList([\n",
    "            AttentiveTransformer(hidden_dim, input_dim)\n",
    "            for _ in range(n_steps)\n",
    "        ])\n",
    "\n",
    "        self.mask_projectors = nn.ModuleList([\n",
    "            nn.Linear(input_dim, hidden_dim)\n",
    "            for _ in range(n_steps)\n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.gamma = gamma\n",
    "        self.sparsity = sparsity\n",
    "        self.register_buffer('prior', torch.ones(1, input_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        features, step_outputs = self.feature_transformer(x)\n",
    "        total_out = 0\n",
    "        prior = self.prior.expand(x.size(0), -1)\n",
    "        masks = []\n",
    "\n",
    "        for step in range(len(self.attentive_trans)):\n",
    "            mask = self.attentive_trans[step](features, prior)\n",
    "            masks.append(mask)\n",
    "\n",
    "            masked_features = x * mask\n",
    "            projected_features = self.mask_projectors[step](masked_features)\n",
    "            features = F.relu(projected_features)\n",
    "\n",
    "            # Используем текущий шаг для step_outputs\n",
    "            total_out += self.fc(step_outputs[step])\n",
    "\n",
    "            prior = prior * (self.gamma - mask)\n",
    "\n",
    "        mask_loss = self.sparsity * torch.mean(\n",
    "            torch.sum(torch.stack([m.mean(dim=0) for m in masks]), dim=0)\n",
    "        )\n",
    "        return total_out.squeeze(), mask_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a057186-2503-485b-b64d-0019be50f2bc",
   "metadata": {},
   "source": [
    "# Train-loop и eval-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fc625dc-3d33-4fdb-b6eb-78f21e7d3a86",
   "metadata": {
    "id": "9fc625dc-3d33-4fdb-b6eb-78f21e7d3a86"
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_loader, val_loader, epochs=30, lr=1e-3):\n",
    "    model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    best_auc = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_preds, train_true = [], []\n",
    "\n",
    "        for x, y in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits, mask_loss = model(x)\n",
    "            loss = criterion(logits, y.squeeze()) + mask_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_preds.extend(torch.sigmoid(logits.detach().cpu()))\n",
    "            train_true.extend(y.cpu().squeeze())\n",
    "\n",
    "        val_auc = eval_model(model, val_loader)\n",
    "        train_auc = roc_auc_score(train_true, train_preds)\n",
    "        print(f\"Epoch {epoch+1} | Train AUC: {train_auc:.4f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8e60a13-45ea-49f9-b405-8cc1f2da78e1",
   "metadata": {
    "id": "b8e60a13-45ea-49f9-b405-8cc1f2da78e1"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, loader):\n",
    "    model.eval()\n",
    "    preds, true = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            logits, _ = model(x)\n",
    "            preds.extend(torch.sigmoid(logits.cpu()))\n",
    "            true.extend(y.squeeze().cpu().numpy())\n",
    "\n",
    "    return roc_auc_score(true, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc5260b-4a49-4a10-9805-e5276b25bd88",
   "metadata": {},
   "source": [
    "# Обучим модель и посмотрим на качество во время обучения\n",
    "\n",
    "Наверное лучше, если есть время, запустить optuna для поиска лучших гиперпараметров и использовать для этого кроссвалидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d571c1f-901a-4b6e-aa6a-4fe4c4f2f942",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d571c1f-901a-4b6e-aa6a-4fe4c4f2f942",
    "outputId": "06a6e6cd-71d3-4e21-cc5c-38e1d02f86d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1:   0%|          | 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 1: 100%|██████████| 375/375 [00:04<00:00, 85.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train AUC: 0.8419 | Val AUC: 0.8790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2:   0%|          | 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 2: 100%|██████████| 375/375 [00:03<00:00, 105.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train AUC: 0.8630 | Val AUC: 0.8833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3:   0%|          | 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 3: 100%|██████████| 375/375 [00:03<00:00, 96.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train AUC: 0.8683 | Val AUC: 0.8815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 4:   0%|          | 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 4: 100%|██████████| 375/375 [00:03<00:00, 113.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train AUC: 0.8743 | Val AUC: 0.8822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 5:   0%|          | 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 5: 100%|██████████| 375/375 [00:03<00:00, 109.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train AUC: 0.8733 | Val AUC: 0.8837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 6:   0%|          | 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 6: 100%|██████████| 375/375 [00:04<00:00, 87.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train AUC: 0.8748 | Val AUC: 0.8805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 7:   0%|          | 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 7: 100%|██████████| 375/375 [00:03<00:00, 113.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train AUC: 0.8767 | Val AUC: 0.8798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 8:   0%|          | 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 8: 100%|██████████| 375/375 [00:03<00:00, 114.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train AUC: 0.8758 | Val AUC: 0.8828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 9:   0%|          | 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 9: 100%|██████████| 375/375 [00:04<00:00, 79.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train AUC: 0.8770 | Val AUC: 0.8810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 10:   0%|          | 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 10: 100%|██████████| 375/375 [00:03<00:00, 112.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train AUC: 0.8792 | Val AUC: 0.8828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 11:   0%|          | 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 11: 100%|██████████| 375/375 [00:03<00:00, 111.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train AUC: 0.8792 | Val AUC: 0.8818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 12:   0%|          | 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 12: 100%|██████████| 375/375 [00:04<00:00, 85.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train AUC: 0.8792 | Val AUC: 0.8844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 13:   0%|          | 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 13: 100%|██████████| 375/375 [00:03<00:00, 103.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train AUC: 0.8785 | Val AUC: 0.8796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 14:   0%|          | 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 14: 100%|██████████| 375/375 [00:03<00:00, 116.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train AUC: 0.8807 | Val AUC: 0.8845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 15:   0%|          | 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 15: 100%|██████████| 375/375 [00:05<00:00, 72.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train AUC: 0.8812 | Val AUC: 0.8831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TabNetClassifier(\n",
       "  (feature_transformer): FeatureTransformer(\n",
       "    (shared): ModuleList(\n",
       "      (0): GLU(\n",
       "        (fc): Linear(in_features=23, out_features=128, bias=True)\n",
       "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1-2): 2 x GLU(\n",
       "        (fc): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (steps): ModuleList(\n",
       "      (0-1): 2 x GLU(\n",
       "        (fc): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attentive_trans): ModuleList(\n",
       "    (0-1): 2 x AttentiveTransformer(\n",
       "      (fc): Linear(in_features=64, out_features=23, bias=True)\n",
       "      (bn): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (mask_projectors): ModuleList(\n",
       "    (0-1): 2 x Linear(in_features=23, out_features=64, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TabNetClassifier(\n",
    "    input_dim=X_train.shape[1],\n",
    "    n_steps=2,\n",
    "    hidden_dim=64,\n",
    "    shared_layers=3,\n",
    "    sparsity=1e-3\n",
    ")\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "train_model(model, optimizer, train_loader, val_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c58e5-b97e-4efb-bae7-7e16c16369b0",
   "metadata": {},
   "source": [
    "# Сделаем финальный submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84bed07c-7915-4ede-b75b-898a5c63f265",
   "metadata": {
    "id": "84bed07c-7915-4ede-b75b-898a5c63f265"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "X_test = scaler.transform(test_df)  # Убедитесь, что колонки совпадают с train\n",
    "\n",
    "test_dataset = CustomDataset(X_test, pd.Series([0]*len(X_test)))  # Фиктивные метки\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69f05976-088b-46a2-89af-aa84b2c4bacb",
   "metadata": {
    "id": "69f05976-088b-46a2-89af-aa84b2c4bacb"
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Получение предсказаний\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for x, _ in test_loader:\n",
    "        x = x.to(device)\n",
    "        logits, _ = model(x)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        test_preds.extend(probs)\n",
    "\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"],\n",
    "    \"smoking\": test_preds  # Или \"predict\", если название колонки должно быть predict\n",
    "})\n",
    "\n",
    "result_df\n",
    "\n",
    "result_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
